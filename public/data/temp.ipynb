{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735a9400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ./datafiles/2016-10-10.csv.gz\n",
      "Processing: ./datafiles/2018-06-26.csv.gz\n",
      "Processing: ./datafiles/2019-04-09.csv.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Settings\n",
    "columns_to_keep = ['ticker', 'exchange', 'participant_timestamp', 'price', 'size']\n",
    "valid_exchanges = {2, 12, 17, 202, 203}\n",
    "output_file = './datafiles/sample_output.csv'\n",
    "\n",
    "# Ensure data directory exists\n",
    "os.makedirs('./datafiles', exist_ok=True)\n",
    "\n",
    "# Remove output file if it exists\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "# Sort files chronologically (alphabetically works for YYYY-MM-DD.csv.gz)\n",
    "data_dir = './datafiles'\n",
    "file_list = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.csv.gz')])\n",
    "\n",
    "# Choose up to 10 random files\n",
    "n = min(10, len(file_list))\n",
    "sample_files = random.sample(file_list, n)\n",
    "sample_files = sorted(sample_files)  # Sort the sample files for consistent output\n",
    "\n",
    "# State for del_t and del_p\n",
    "last_seen = {}  # {ticker: (last_timestamp, last_price)}\n",
    "header_written = False\n",
    "\n",
    "for file in sample_files:\n",
    "    print(\"Processing:\", file)\n",
    "    with gzip.open(file, 'rt') as f:\n",
    "        df = pd.read_csv(f, usecols=columns_to_keep)\n",
    "    # Filter valid exchanges and deduplicate\n",
    "    df = df[df['exchange'].isin(valid_exchanges)].drop_duplicates()\n",
    "    # Sort by participant_timestamp\n",
    "    df = df.sort_values('participant_timestamp').reset_index(drop=True)\n",
    "    # Compute del_t and del_p\n",
    "    del_t_list = []\n",
    "    del_p_list = []\n",
    "    for idx, row in df.iterrows():\n",
    "        ticker = row['ticker']\n",
    "        timestamp = row['participant_timestamp']\n",
    "        price = row['price']\n",
    "        if ticker in last_seen:\n",
    "            last_time, last_price = last_seen[ticker]\n",
    "            del_t = timestamp - last_time\n",
    "            del_p = price - last_price\n",
    "        else:\n",
    "            del_t = 0\n",
    "            del_p = 0\n",
    "        last_seen[ticker] = (timestamp, price)\n",
    "        del_t_list.append(del_t)\n",
    "        del_p_list.append(del_p)\n",
    "    df['del_t'] = del_t_list\n",
    "    df['del_p'] = del_p_list\n",
    "    # Write to sample output file\n",
    "    df.to_csv(output_file, mode='a', header=not header_written, index=False)\n",
    "    header_written = True\n",
    "\n",
    "print(f\"Sample written to {output_file} ({n} files)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550cd351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "# Hardcoded date file\n",
    "DATE = \"2019-08-26\"\n",
    "date_file = f\"./datafiles/{DATE}.csv.gz\"\n",
    "\n",
    "# Files\n",
    "output_file = \"./datafiles/output.csv\"\n",
    "output2_tmp = \"./datafiles/output2.csv.tmp\"\n",
    "\n",
    "# Parameters\n",
    "CHUNK_SIZE = 10_000_000  # rows per chunk\n",
    "\n",
    "# --- 1) load the date file, sort by timestamp, get first timestamp\n",
    "if not os.path.exists(date_file):\n",
    "    print(f\"Date file not found: {date_file}\")\n",
    "    raise SystemExit(1)\n",
    "\n",
    "print(\"Reading date file:\", date_file)\n",
    "with gzip.open(date_file, \"rt\") as f:\n",
    "    df_date = pd.read_csv(f, usecols=[\"participant_timestamp\"])\n",
    "\n",
    "# sort and get first timestamp (ascending)\n",
    "df_date = df_date.sort_values(\"participant_timestamp\").reset_index(drop=True)\n",
    "first_ts = int(df_date.iloc[0][\"participant_timestamp\"])\n",
    "print(\"Cutoff timestamp (first entry):\", first_ts)\n",
    "\n",
    "# --- 2) iterate output.csv in chunks and write rows with timestamp < first_ts into output2_tmp\n",
    "if not os.path.exists(output_file):\n",
    "    print(f\"Output file not found: {output_file}\")\n",
    "    raise SystemExit(1)\n",
    "\n",
    "# Ensure any previous tmp is removed\n",
    "if os.path.exists(output2_tmp):\n",
    "    os.remove(output2_tmp)\n",
    "\n",
    "writer_header_written = False\n",
    "processed_rows = 0\n",
    "\n",
    "print(\"Streaming\", output_file, \"->\", output2_tmp)\n",
    "for chunk in pd.read_csv(output_file, chunksize=CHUNK_SIZE):\n",
    "    # ensure participant_timestamp is int-like\n",
    "    if chunk[\"participant_timestamp\"].dtype != \"int64\" and chunk[\"participant_timestamp\"].dtype != \"int32\":\n",
    "        chunk[\"participant_timestamp\"] = pd.to_numeric(chunk[\"participant_timestamp\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    # select rows before cutoff\n",
    "    valid = chunk[chunk[\"participant_timestamp\"] < first_ts]\n",
    "    if not valid.empty:\n",
    "        # write header only for first write\n",
    "        valid.to_csv(output2_tmp, mode=\"a\", header=not writer_header_written, index=False)\n",
    "        writer_header_written = True\n",
    "        processed_rows += len(valid)\n",
    "    # if any row in this chunk has timestamp >= first_ts, we stop processing further chunks\n",
    "    if (chunk[\"participant_timestamp\"] >= first_ts).any():\n",
    "        print(\"Encountered rows >= cutoff in chunk; stopping after writing valid rows from this chunk.\")\n",
    "        break\n",
    "\n",
    "print(f\"Rows written to temporary file: {processed_rows}\")\n",
    "\n",
    "# --- 3) replace original output.csv with output2 (delete and rename as requested)\n",
    "# remove original and atomically replace with tmp\n",
    "try:\n",
    "    os.remove(output_file)\n",
    "    print(\"Deleted original output file.\")\n",
    "except Exception as e:\n",
    "    print(\"Warning: could not delete original output file:\", e)\n",
    "\n",
    "# If no rows were written, create an empty CSV with header from original (optional)\n",
    "if not writer_header_written:\n",
    "    # try to get header from original by reading small sample\n",
    "    sample = pd.read_csv(output_file, nrows=0) if os.path.exists(output_file) else None\n",
    "    if sample is not None:\n",
    "        sample.to_csv(output2_tmp, index=False)\n",
    "    else:\n",
    "        # nothing to do; create empty file\n",
    "        open(output2_tmp, \"w\").close()\n",
    "\n",
    "# rename tmp to output\n",
    "os.replace(output2_tmp, output_file)\n",
    "print(\"Replaced output with pruned temporary file.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
